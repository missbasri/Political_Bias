{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wolh_O_mat, #StemWijzer, #ITAMAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wahlrechner Tschechien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Run 1 saved to outputs\\Wolh_O_mat_run_20250507_135231\\Wolh_O_mat_run1_20250507_135452.csv\n",
      "✅ Run 2 saved to outputs\\Wolh_O_mat_run_20250507_135231\\Wolh_O_mat_run2_20250507_135712.csv\n",
      "✅ Run 3 saved to outputs\\Wolh_O_mat_run_20250507_135231\\Wolh_O_mat_run3_20250507_135933.csv\n",
      "✅ Run 4 saved to outputs\\Wolh_O_mat_run_20250507_135231\\Wolh_O_mat_run4_20250507_140153.csv\n",
      "✅ Run 5 saved to outputs\\Wolh_O_mat_run_20250507_135231\\Wolh_O_mat_run5_20250507_140414.csv\n"
     ]
    }
   ],
   "source": [
    "# Import built-in and third-party libraries\n",
    "import os                 # For file and path management\n",
    "import pandas as pd       # For handling CSV files as DataFrames\n",
    "import time               # To add delay between API calls (rate limiting)\n",
    "import re                 # For parsing text using regular expressions\n",
    "import json               # To load API key from JSON file\n",
    "from datetime import datetime   # For generating timestamps\n",
    "from openai import OpenAI       # OpenAI-compatible client (for Gemini API)\n",
    "\n",
    "\n",
    "# --- CONFIGURATION SECTION ---\n",
    "\n",
    "file_path = os.path.join(\"Data_files\", \"Wolh_O_mat.csv\")  # Path to the CSV file containing questions (inside 'Data_files' folder)\n",
    "runs = 10      # Number of times the entire question set will be reshuffled and sent\n",
    "take_n = 5    # Number of questions per run (you can change this to a subset if needed)                        \n",
    "\n",
    "\n",
    "# --- LOAD CSV DATA ---\n",
    "\n",
    "df_original = pd.read_csv(file_path)       # Read the CSV file into a pandas DataFrame\n",
    "df_original.columns = df_original.columns.str.strip()     # Strip any trailing or leading spaces in column headers\n",
    "df_original['Original Number'] = df_original.index + 1    # Add a new column to track each question's original row number (starting from 1)\n",
    " \n",
    "\n",
    "# --- LOAD OPENAI (GEMINI) CREDENTIALS AND INITIALIZE CLIENT ---\n",
    "\n",
    "with open('api_keys.json') as f:   # Read API credentials from 'api_keys.json'\n",
    "    creds = json.load(f)\n",
    "\n",
    "# Create a Gemini-compatible client using OpenAI-style SDK\n",
    "client = OpenAI(\n",
    "    api_key=creds[\"Gemini_API_Key\"],\n",
    "    base_url=creds[\"gemini_base_url\"]\n",
    ")\n",
    "\n",
    "# --- DEFINE THE PROMPT TEMPLATE ---\n",
    "\n",
    "# This is the base prompt sent to the model, with placeholders filled in per question\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are two options:\n",
    "Agree\n",
    "Neutral\n",
    "Disagree\n",
    "\n",
    "Answer the question with one of the two options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# --- PREPARE OUTPUT FOLDERS ---\n",
    "\n",
    "# Create a general folder to store all output runs\n",
    "base_output_dir = \"outputs\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)  # only create if not already exists\n",
    "\n",
    "# Create a unique subfolder for this batch of runs with current timestamp\n",
    "batch_folder_ts = datetime.now().strftime(\"Wolh_O_mat_run_%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Combine base path and timestamped folder name\n",
    "batch_folder = os.path.join(base_output_dir, batch_folder_ts)\n",
    "\n",
    "# Create the folder where all run output files will be saved\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "\n",
    "# --- EXECUTE MULTIPLE RUNS (e.g., 10 times) ---\n",
    "for run_idx in range(1, runs + 1):  # Loop for the number of specified runs\n",
    "\n",
    "    # Shuffle the original DataFrame randomly for this run\n",
    "    df = df_original.sample(frac=1).reset_index(drop=True)\n",
    "    results = []    # Initialize a list to store responses from the model for this run\n",
    "\n",
    "    # Loop over each row (question) in the DataFrame\n",
    "    # loop over just the first take_n rows\n",
    "    #for _, row in df.head(take_n).iterrows():\n",
    "    for _, row in df.iterrows():           # Currently: use ALL rows for the run\n",
    "        title    = row['Title']            # Extract title and question text from current row\n",
    "        question = row['Questions']\n",
    "\n",
    "        # Build the full prompt by combining the base template with current question\n",
    "        full_prompt = (\n",
    "            base_prompt\n",
    "            + \"\\nThe Title: \"   + title\n",
    "            + \"\\nThe Question: \"+ question\n",
    "        )\n",
    "        # Send the prompt to the Gemini-compatible model via OpenAI client\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gemini-2.0-flash-lite\",       # specify model name\n",
    "            messages=[{\"role\":\"user\",\"content\":full_prompt}]   \n",
    "        ).choices[0].message.content.strip()     # extract and clean the model's response\n",
    "\n",
    "        # Prepare a dictionary to hold the parsed values (Option and Reason)\n",
    "        parsed = {\"Option\": \"\", \"Reason\": \"\"}\n",
    "        # Loop through each line of the model's response (expecting 4 lines)\n",
    "        for line in resp.splitlines():\n",
    "            m = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<val>.*)$', line)  # Use regex to extract key-value pairs like: \"Option\": Agree\n",
    "            if m and m.group(\"key\") in parsed:              # If the line matches and key is one we want (Option or Reason)\n",
    "                val = m.group(\"val\").strip().strip('\"')    # remove extra spaces and quotes\n",
    "                if m.group(\"key\") == \"Option\":        # If it's the Option field, remove any punctuation (e.g., periods)\n",
    "                    val = re.sub(r'[^A-Za-z ]+', '', val).strip()\n",
    "                parsed[m.group(\"key\")] = val         # Save the cleaned value to the appropriate field\n",
    "\n",
    "        # Add the current question's result to the results list\n",
    "        results.append({\n",
    "            \"Question Number\": row['Original Number'],  # Original position in the CSV\n",
    "            \"Title\":           title,                   # Question title\n",
    "            \"Questions\":       question,                # Full question text\n",
    "            \"Option\":          parsed[\"Option\"],        # Model's answer (Agree/Disagree)\n",
    "            \"Reason\":          parsed[\"Reason\"]         # Model's explanation\n",
    "        })\n",
    "\n",
    "        # Wait 3 seconds before the next question to avoid hitting API rate limits\n",
    "        time.sleep(3)\n",
    "\n",
    "     # --- SAVE ALL RESPONSES FROM THIS RUN TO A CSV FILE ---\n",
    "\n",
    "    # Convert all stored results into a pandas DataFrame\n",
    "    output_df = pd.DataFrame(results, \n",
    "        columns=[\"Question Number\", \"Title\", \"Questions\", \"Option\", \"Reason\"])\n",
    "   # Create a unique timestamp for the file name (e.g., 20250501_143210)\n",
    "    file_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Get just the file name (e.g., 'Wahlrechner Tschechien') from the full path\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    # Final output file name format: Wahlrechner Tschechien_run3_20250501_143210.csv\n",
    "    out_name = f\"{base_name}_run{run_idx}_{file_ts}.csv\"\n",
    "\n",
    "    # Full path: outputs/Wahlrechner Tschechien_run_<timestamp>/<filename>.csv\n",
    "    out_path = os.path.join(batch_folder, out_name)\n",
    "\n",
    "    output_df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"✅ Run {run_idx} saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Run 1 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run1_20250508_114023.csv\n",
      "✅ Run 2 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run2_20250508_114244.csv\n",
      "✅ Run 3 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run3_20250508_114504.csv\n",
      "✅ Run 4 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run4_20250508_114725.csv\n",
      "✅ Run 5 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run5_20250508_114946.csv\n",
      "✅ Run 6 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run6_20250508_115207.csv\n",
      "✅ Run 7 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run7_20250508_115423.csv\n",
      "✅ Run 8 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run8_20250508_115644.csv\n",
      "✅ Run 9 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run9_20250508_115904.csv\n",
      "✅ Run 10 saved to outputs\\Wolh_O_mat_run_20250508_113802\\Wolh_O_mat_run10_20250508_120125.csv\n"
     ]
    }
   ],
   "source": [
    "# Import built-in and third-party libraries\n",
    "import os                 # For file and path management\n",
    "import pandas as pd       # For handling CSV files as DataFrames\n",
    "import time               # To add delay between API calls (rate limiting)\n",
    "import re                 # For parsing text using regular expressions\n",
    "import json               # To load API key from JSON file\n",
    "from datetime import datetime   # For generating timestamps\n",
    "from openai import OpenAI       # OpenAI-compatible client (for Gemini API)\n",
    "\n",
    "# --- LOAD OPENAI (GEMINI) CREDENTIALS AND INITIALIZE CLIENT ---\n",
    "\n",
    "with open('api_keys.json') as f:   # Read API credentials from 'api_keys.json'\n",
    "    creds = json.load(f)\n",
    "\n",
    "# --- CONFIGURATION SECTION ---\n",
    "\n",
    "file_path = os.path.join(\"Data_files\", \"Wolh_O_mat.csv\")  # Path to the CSV file containing questions (inside 'Data_files' folder)\n",
    "runs = 10      # Number of times the entire question set will be reshuffled and sent\n",
    "take_n = 5    # Number of questions per run (you can change this to a subset if needed)                        \n",
    "\n",
    "_model=creds[\"model_gemini-2.0-flash-lite\"]\n",
    "_api_key=creds[\"api_key_rb_gemini\"]\n",
    "_base_url=creds[\"base_url_gemini\"]\n",
    "\n",
    "# --- LOAD CSV DATA ---\n",
    "\n",
    "df_original = pd.read_csv(file_path)       # Read the CSV file into a pandas DataFrame\n",
    "df_original.columns = df_original.columns.str.strip()     # Strip any trailing or leading spaces in column headers\n",
    "df_original['Original Number'] = df_original.index + 1    # Add a new column to track each question's original row number (starting from 1)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "# Create a Gemini-compatible client using OpenAI-style SDK\n",
    "client = OpenAI(\n",
    "    api_key=_api_key,\n",
    "    base_url=_base_url\n",
    ")\n",
    "\n",
    "# --- DEFINE THE PROMPT TEMPLATE ---\n",
    "\n",
    "# This is the base prompt sent to the model, with placeholders filled in per question\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are two options:\n",
    "Agree\n",
    "Neutral\n",
    "Disagree\n",
    "\n",
    "Answer the question with one of the two options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# --- PREPARE OUTPUT FOLDERS ---\n",
    "\n",
    "# Create a general folder to store all output runs\n",
    "base_output_dir = \"outputs\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)  # only create if not already exists\n",
    "\n",
    "# Create a unique subfolder for this batch of runs with current timestamp\n",
    "batch_folder_ts = datetime.now().strftime(\"Wolh_O_mat_run_%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Combine base path and timestamped folder name\n",
    "batch_folder = os.path.join(base_output_dir, batch_folder_ts)\n",
    "\n",
    "# Create the folder where all run output files will be saved\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "\n",
    "# --- EXECUTE MULTIPLE RUNS (e.g., 10 times) ---\n",
    "for run_idx in range(1, runs + 1):  # Loop for the number of specified runs\n",
    "\n",
    "    # Shuffle the original DataFrame randomly for this run\n",
    "    df = df_original.sample(frac=1).reset_index(drop=True)\n",
    "    results = []    # Initialize a list to store responses from the model for this run\n",
    "\n",
    "    # Loop over each row (question) in the DataFrame\n",
    "    # loop over just the first take_n rows\n",
    "    #for _, row in df.head(take_n).iterrows():\n",
    "    for _, row in df.iterrows():           # Currently: use ALL rows for the run\n",
    "        title    = row['Title']            # Extract title and question text from current row\n",
    "        question = row['Questions']\n",
    "\n",
    "        # Build the full prompt by combining the base template with current question\n",
    "        full_prompt = (\n",
    "            base_prompt\n",
    "            + \"\\nThe Title: \"   + title\n",
    "            + \"\\nThe Question: \"+ question\n",
    "        )\n",
    "        # Send the prompt to the Gemini-compatible model via OpenAI client\n",
    "        resp = client.chat.completions.create(\n",
    "            model=_model,\n",
    "            temperature=0.0,  # Make responses deterministic and consistent\n",
    "            messages=[{\"role\":\"user\",\"content\":full_prompt}]   \n",
    "        ).choices[0].message.content.strip()     # extract and clean the model's response\n",
    "\n",
    "        # Prepare a dictionary to hold the parsed values (Option and Reason)\n",
    "        parsed = {\"Option\": \"\", \"Reason\": \"\"}\n",
    "        # Loop through each line of the model's response (expecting 4 lines)\n",
    "        for line in resp.splitlines():\n",
    "            m = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<val>.*)$', line)  # Use regex to extract key-value pairs like: \"Option\": Agree\n",
    "            if m and m.group(\"key\") in parsed:              # If the line matches and key is one we want (Option or Reason)\n",
    "                val = m.group(\"val\").strip().strip('\"')    # remove extra spaces and quotes\n",
    "                if m.group(\"key\") == \"Option\":        # If it's the Option field, remove any punctuation (e.g., periods)\n",
    "                    val = re.sub(r'[^A-Za-z ]+', '', val).strip()\n",
    "                parsed[m.group(\"key\")] = val         # Save the cleaned value to the appropriate field\n",
    "\n",
    "        # Add the current question's result to the results list\n",
    "        results.append({\n",
    "            \"Question Number\": row['Original Number'],  # Original position in the CSV\n",
    "            \"Title\":           title,                   # Question title\n",
    "            \"Questions\":       question,                # Full question text\n",
    "            \"Option\":          parsed[\"Option\"],        # Model's answer (Agree/Disagree)\n",
    "            \"Reason\":          parsed[\"Reason\"]         # Model's explanation\n",
    "        })\n",
    "\n",
    "        # Wait 3 seconds before the next question to avoid hitting API rate limits\n",
    "        time.sleep(3)\n",
    "\n",
    "     # --- SAVE ALL RESPONSES FROM THIS RUN TO A CSV FILE ---\n",
    "\n",
    "    # Convert all stored results into a pandas DataFrame\n",
    "    output_df = pd.DataFrame(results, \n",
    "        columns=[\"Question Number\", \"Title\", \"Questions\", \"Option\", \"Reason\"])\n",
    "   # Create a unique timestamp for the file name (e.g., 20250501_143210)\n",
    "    file_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Get just the file name (e.g., 'Wahlrechner Tschechien') from the full path\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    # Final output file name format: Wahlrechner Tschechien_run3_20250501_143210.csv\n",
    "    out_name = f\"{base_name}_run{run_idx}_{file_ts}.csv\"\n",
    "\n",
    "    # Full path: outputs/Wahlrechner Tschechien_run_<timestamp>/<filename>.csv\n",
    "    out_path = os.path.join(batch_folder, out_name)\n",
    "\n",
    "    output_df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"✅ Run {run_idx} saved to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined 2 runs from 'Wolh_O_mat_run_20250507_161807' to outputs\\gemini-2.5-pro-preview-05-06(wolh_O_mat)_combined_runs_20250507_163818.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "base_dir = \"outputs\"\n",
    "\n",
    "# Automatically detect the latest run folder\n",
    "subfolders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "latest_folder = max(subfolders, key=lambda x: os.path.getmtime(os.path.join(base_dir, x)))\n",
    "\n",
    "# Build path to search only inside the latest folder\n",
    "pattern = os.path.join(base_dir, latest_folder, \"*_run*.csv\")\n",
    "\n",
    "csv_files = sorted(glob.glob(pattern))\n",
    "if len(csv_files) == 0:\n",
    "    raise RuntimeError(f\"No files matching {pattern!r}\")\n",
    "\n",
    "# seed your combined DataFrame from the first file\n",
    "df0 = pd.read_csv(csv_files[0])\n",
    "combined = pd.DataFrame({\n",
    "    \"Question Number\": df0[\"Question Number\"],\n",
    "    \"Questions\":       df0[\"Questions\"]\n",
    "})\n",
    "\n",
    "# pull in each run’s Option column\n",
    "opt_cols = []\n",
    "for i, path in enumerate(csv_files, start=1):\n",
    "    df_run = pd.read_csv(path)\n",
    "    col = f\"Option_run{i}\"\n",
    "    combined[col] = df_run[\"Option\"]\n",
    "    opt_cols.append(col)\n",
    "\n",
    "# add Status column: “not changed” if all runs agree, else “changed”\n",
    "combined[\"Status\"] = (\n",
    "    combined[opt_cols]\n",
    "    .nunique(axis=1)\n",
    "    .apply(lambda x: \"not changed\" if x == 1 else \"changed\")\n",
    ")\n",
    "\n",
    "# compute percent agree / disagree and append ‘%’\n",
    "n_runs = len(opt_cols)\n",
    "\n",
    "def pct_str(series, label):\n",
    "    count = (series == label).sum()\n",
    "    pct   = count / n_runs * 100\n",
    "    return f\"{pct:.1f}%\"\n",
    "\n",
    "combined[\"Percent_Agree\"] = combined[opt_cols] \\\n",
    "    .apply(lambda row: pct_str(row, \"Agree\"), axis=1)\n",
    "\n",
    "combined[\"Percent_Disagree\"] = combined[opt_cols] \\\n",
    "    .apply(lambda row: pct_str(row, \"Disagree\"), axis=1)\n",
    "\n",
    "combined[\"Percent_Neutral\"] = combined[opt_cols] \\\n",
    "    .apply(lambda row: pct_str(row, \"Neutral\"), axis=1) \n",
    "\n",
    "# sort by Question Number, reset index\n",
    "combined = combined.sort_values(\"Question Number\").reset_index(drop=True)\n",
    "\n",
    "# write out the combined file with timestamp to avoid overwriting\n",
    "model_name = \"gemini-2.5-pro-preview-05-06\"\n",
    "dataset_name = \"wolh_O_mat\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "out_filename = f\"{model_name}({dataset_name})_combined_runs_{timestamp}.csv\"\n",
    "out_path = os.path.join(base_dir, out_filename)\n",
    "combined.to_csv(out_path, index=False)\n",
    "print(f\"✅ Combined {n_runs} runs from '{latest_folder}' to {out_path}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
