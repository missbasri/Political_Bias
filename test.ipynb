{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wolh_O_mat, #StemWijzer, #ITAMAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🟡 (1) Support for Ukraine: Germany should continue to provide military support to Ukraine.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Support for Ukraine\n",
      "\"Questions\": Germany should continue to provide military support to Ukraine.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Supporting Ukraine's defense against aggression is crucial for European security and stability.\n",
      "\n",
      "\n",
      "🟡 (2) Renewable Energies: The expansion of renewable energies should continue to be financially supported by the state.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Renewable Energies\n",
      "\"Questions\": The expansion of renewable energies should continue to be financially supported by the state.\n",
      "\"Option\": Agree\n",
      "\"Reason\": State support accelerates innovation and deployment, aiding a transition to sustainable and cleaner energy sources.\n",
      "\n",
      "\n",
      "🟡 (3) Cancellation of the Citizen’s Allowan: Citizens’ benefit are to be withdrawn from those who repeatedly reject job offer\n",
      "🟢 Raw Response:\n",
      "\"Title\": Cancellation of the Citizen’s Allowance\n",
      "\"Questions\": Citizens’ benefit are to be withdrawn from those who repeatedly reject job offer\n",
      "\"Option\": Agree\n",
      "\"Reason\":  Individuals should be incentivized to seek employment; repeated refusal shows lack of effort.\n",
      "\n",
      "\n",
      "🟡 (4) Speed limit on motorways: A general speed limit should apply on all motorways.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Speed limit on motorways\n",
      "\"Questions\": A general speed limit should apply on all motorways.\n",
      "\"Option\": Agree\n",
      "\"Reason\": It promotes safety and consistency, reducing accidents by setting a clear, enforced standard for drivers.\n",
      "\n",
      "\n",
      "🟡 (5) Rejection of asylum seekers: Asylum seekers who have entered the country via another EU country will be turned away at the German border.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Rejection of asylum seekers\n",
      "\"Questions\": Asylum seekers who have entered the country via another EU country will be turned away at the German border.\n",
      "\"Option\": Agree\n",
      "\"Reason\": This reflects current EU regulations, where asylum claims are typically handled in the first safe country.\n",
      "\n",
      "\n",
      "🟡 (6) Limitation of rental prices: For new rentals, rental prices should continue to be capped by law.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Limitation of rental prices\n",
      "\"Questions\": For new rentals, rental prices should continue to be capped by law.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Price caps can stifle new construction, ultimately limiting the supply of available housing.\n",
      "\n",
      "\n",
      "🟡 (7) Automated facial recognition: The Federal Police should be allowed to use software for automated facial recognition at railway stations.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Automated facial recognition\n",
      "\"Questions\": The Federal Police should be allowed to use software for automated facial recognition at railway stations.\n",
      "\"Option\": Agree\n",
      "\"Reason\":  It can enhance security and help prevent crime, although privacy concerns need to be addressed.\n",
      "\n",
      "\n",
      "🟡 (8) Energy-intensive companies compensation: Energy-intensive companies should receive financial compensation from the state for their electricity costs.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Energy-intensive companies compensation\n",
      "\"Questions\": Energy-intensive companies should receive financial compensation from the state for their electricity costs.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Compensation can help maintain competitiveness and prevent job losses in industries vital to the economy.\n",
      "\n",
      "\n",
      "🟡 (9) Pension after 40 years of contributions: All employees should be able to retire without deductions after.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Pension after 40 years of contributions\n",
      "\"Questions\": All employees should be able to retire without deductions after 40 years.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Contributions deserve full benefits after a substantial period of dedicated work for retirement.\n",
      "\n",
      "\n",
      "🟡 (10) Article 38 of the Basic Law: The introductory sentence of the Basic Law should continue to contain the phrase “responsibility before God\n",
      "🟢 Raw Response:\n",
      "\"Title\": Article 38 of the Basic Law\n",
      "\"Questions\": The introductory sentence of the Basic Law should continue to contain the phrase “responsibility before God”.\n",
      "\"Option\": Neutral\n",
      "\"Reason\":  This phrase is important to some, but not necessarily essential for all citizens to agree with.\n",
      "\n",
      "\n",
      "🟡 (11) Recruitment of skilled workers: Germany should continue to promote the recruitment of skilled workers from abroad.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Recruitment of skilled workers\n",
      "\"Questions\": Germany should continue to promote the recruitment of skilled workers from abroad.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Skilled workers from abroad help fill labor shortages and boost economic growth in Germany.\n",
      "\n",
      "\n",
      "🟡 (12) Use of nuclear energy: Germany should again use nuclear energy to generate electricity.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Use of nuclear energy\n",
      "\"Questions\": Germany should again use nuclear energy to generate electricity.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Nuclear energy poses safety and waste disposal challenges that outweigh its benefits for Germany.\n",
      "\n",
      "\n",
      "🟡 (13) Raising the top tax rate: The top tax rate on income is to be increased.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Raising the top tax rate\n",
      "\"Questions\": The top tax rate on income is to be increased.\n",
      "\"Option\": Neutral\n",
      "\"Reason\": The impact depends on specific details and economic conditions; needs more information.\n",
      "\n",
      "\n",
      "🟡 (14) Competencies in School Policy: The federal government should be given more powers in school policy.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Competencies in School Policy\n",
      "\"Questions\": The federal government should be given more powers in school policy.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Local control fosters innovation and better reflects community needs than centralized federal mandates.\n",
      "\n",
      "\n",
      "🟡 (15) Arms exports to Israel: Germany should continue to be allowed to export military equipment to Israel.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Arms exports to Israel\n",
      "\"Questions\": Germany should continue to be allowed to export military equipment to Israel.\n",
      "\"Option\": Neutral\n",
      "\"Reason\": The situation is complex; balancing security needs and ethical considerations requires careful assessment.\n",
      "\n",
      "\n",
      "🟡 (16) Health insurance companies: All citizens should be required to be insured in statutory health insurance funds.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Health insurance companies\n",
      "\"Questions\": All citizens should be required to be insured in statutory health insurance funds.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Ensures access to healthcare for all, promoting public health and preventing financial hardship due to illness.\n",
      "\n",
      "\n",
      "🟡 (17) Abolition of the women’s quo: The statutory quota for women on executive boards and supervisory boards of listed companies is to be abolished.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Abolition of the women’s quota\n",
      "\"Questions\": The statutory quota for women on executive boards and supervisory boards of listed companies is to be abolished.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Removing quotas could hinder progress towards gender equality in leadership positions, potentially setting back advancements.\n",
      "\n",
      "\n",
      "🟡 (18) Organic Farming: Organic farming should be promoted more than conventional farming.\n",
      "🟢 Raw Response:\n",
      "Here's the output:\n",
      "\n",
      "\"Title\": Organic Farming\n",
      "\"Questions\": Organic farming should be promoted more than conventional farming.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Organic farming offers environmental benefits and reduces harmful chemical use, making it preferable.\n",
      "\n",
      "\n",
      "🟡 (19) Projects against right-wing extremism: The federal government should increase its support for projects against right-wing extremism.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Projects against right-wing extremism\n",
      "\"Questions\": The federal government should increase its support for projects against right-wing extremism.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Right-wing extremism poses a threat; increased support aids prevention and mitigation efforts.\n",
      "\n",
      "\n",
      "🟡 (20) Control of suppliers: Companies should continue to be required to monitor compliance with human rights and environmental protection among all suppliers.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Control of suppliers\n",
      "\"Questions\": Companies should continue to be required to monitor compliance with human rights and environmental protection among all suppliers.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Monitoring supplier practices is crucial for ethical sourcing and ensuring sustainable business operations across the board.\n",
      "\n",
      "\n",
      "🟡 (21) Parent-dependent BAfö: The BAföG training grant will continue to be paid depending on the parents’ inco\n",
      "🟢 Raw Response:\n",
      "Here's an example output based on your instructions:\n",
      "\n",
      "\"Title\": Parent-dependent BAföG\n",
      "\"Questions\": The BAföG training grant will continue to be paid depending on the parents’ income.\n",
      "\"Option\": Agree\n",
      "\"Reason\": This is the core principle of BAföG, as parental income influences eligibility and amount.\n",
      "\n",
      "\n",
      "🟡 (22) Debt brake: The debt brake in the Basic Law should be retained.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Debt brake\n",
      "\"Questions\": The debt brake in the Basic Law should be retained.\n",
      "\"Option\": Agree\n",
      "\"Reason\": It promotes fiscal responsibility and helps to ensure sustainable government spending for future generations.\n",
      "\n",
      "\n",
      "🟡 (23) Work permit for asylum seekers: Asylum seekers in Germany should receive a work permit immediately after submitting their application.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Work permit for asylum seekers\n",
      "\"Questions\": Asylum seekers in Germany should receive a work permit immediately after submitting their application.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Immediate work permits could strain resources and potentially undermine fair processing of asylum claims.\n",
      "\n",
      "\n",
      "🟡 (24) Rejection of climate targets: Germany should abandon the goal of becoming climate neutral.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Rejection of climate targets\n",
      "\"Questions\": Germany should abandon the goal of becoming climate neutral.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Abandoning climate neutrality undermines global efforts to mitigate climate change and its devastating impacts.\n",
      "\n",
      "\n",
      "🟡 (25) 35-hour week: In Germany, the 35-hour week is to be established as the statutory standard working time for all employees.\n",
      "🟢 Raw Response:\n",
      "\"Title\": 35-hour week\n",
      "\"Questions\": In Germany, the 35-hour week is to be established for all employees.\n",
      "\"Option\": Neutral\n",
      "\"Reason\": Implementation specifics and potential impact are unclear, requiring more information for an informed opinion.\n",
      "\n",
      "\n",
      "🟡 (26) Abortions after counseling: Abortions in the first three months of pregnancy should continue to be legal only after counseling.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Abortions after counseling\n",
      "\"Questions\": Abortions in the first three months of pregnancy should continue to be legal only after counseling.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Counseling ensures informed decisions, balancing autonomy with potential support and understanding of options.\n",
      "\n",
      "\n",
      "🟡 (27) National currency: The euro is to be replaced by a national currency in Germany.\n",
      "🟢 Raw Response:\n",
      "\"Title\": National currency\n",
      "\"Questions\": The euro is to be replaced by a national currency in Germany.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Germany's economic ties make a national currency replacement highly unlikely and disruptive.\n",
      "\n",
      "\n",
      "🟡 (28) Rail before road: When expanding transport infrastructure, rail should have priority over road.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Rail before road\n",
      "\"Questions\": When expanding transport infrastructure, rail should have priority over road.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Rail offers greater capacity and often reduces environmental impact compared to road infrastructure expansion.\n",
      "\n",
      "\n",
      "🟡 (29) Volunteers: Voluntary work should be credited towards future pensions.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Volunteers\n",
      "\"Questions\": Voluntary work should be credited towards future pensions.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Volunteers contribute valuable time; crediting towards pensions acknowledges their service and dedication.\n",
      "\n",
      "\n",
      "🟡 (30) Allocation of property tax: The property tax should continue to be passed on to tenants.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Allocation of property tax\n",
      "\"Questions\": The property tax should continue to be passed on to tenants.\n",
      "\"Option\": Neutral\n",
      "\"Reason\": Passing on property tax impacts both landlords and tenants; a neutral stance acknowledges the complexity.\n",
      "\n",
      "\n",
      "🟡 (31) Restriction of the right to strike: The right to strike for employees in critical infrastructure companies is to be restricted by law.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Restriction of the right to strike\n",
      "\"Questions\": The right to strike for employees in critical infrastructure companies is to be restricted by law.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Public safety and essential services should be prioritized, and strikes in key areas can cause significant harm.\n",
      "\n",
      "\n",
      "🟡 (32) Referendums: In Germany, referendums should be possible at the federal level.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Referendums\n",
      "\"Questions\": In Germany, referendums should be possible at the federal level.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Increased citizen participation and direct democracy can enhance government accountability and responsiveness.\n",
      "\n",
      "\n",
      "🟡 (33) Criminal law for children under 14: Children under the age of 14 should be able to be prosecuted.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Criminal law for children under 14\n",
      "\"Questions\": Children under the age of 14 should be able to be prosecuted.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Children under 14 often lack full understanding of consequences and moral reasoning.\n",
      "\n",
      "\n",
      "🟡 (34) Abolition of customs duties: Germany should campaign for the abolition of increased EU tariffs on Chinese electric cars.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Abolition of customs duties\n",
      "\"Questions\": Germany should campaign for the abolition of increased EU tariffs on Chinese electric cars.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Free trade generally benefits consumers and promotes competition, reducing costs and fostering innovation in the market.\n",
      "\n",
      "\n",
      "🟡 (35) Second citizenship: In Germany, it should generally continue to be possible to have a second citizenship in addition to German one.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Second citizenship\n",
      "\"Questions\": In Germany, it should generally continue to be possible to have a second citizenship in addition to German one.\n",
      "\"Option\": Agree\n",
      "\"Reason\": Allows for flexibility in personal lives and can benefit integration for people with dual-national ties.\n",
      "\n",
      "\n",
      "🟡 (36) Compulsory social year: A compulsory social year should be introduced for young adults.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Compulsory social year\n",
      "\"Questions\": A compulsory social year should be introduced for young adults.\n",
      "\"Option\": Agree\n",
      "\"Reason\": It could foster empathy, provide valuable experience, and strengthen community bonds among young adults.\n",
      "\n",
      "\n",
      "🟡 (37) Fossil fuels: New heating systems should continue to be allowed to run entirely on fossil fuels (e.g. gas or oil) in the future.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Fossil fuels\n",
      "\"Questions\": New heating systems should continue to be allowed to run entirely on fossil fuels.\n",
      "\"Option\": Disagree\n",
      "\"Reason\": Transitioning away from fossil fuels is crucial for reducing emissions and mitigating climate change.\n",
      "\n",
      "\n",
      "🟡 (38) Increase in the minimum wage: The statutory minimum wage is to be increased to 15 euros by 2026 at the latest.\n",
      "🟢 Raw Response:\n",
      "\"Title\": Increase in the minimum wage\n",
      "\"Questions\": The statutory minimum wage is to be increased to 15 euros by 2026 at the latest.\n",
      "\"Option\": Neutral\n",
      "\"Reason\": The impact is uncertain; potential benefits & drawbacks exist depending on economic conditions and job markets.\n",
      "\n",
      "\n",
      "✅ Saved to Wolh_O_mat_gemini_answers_formatted.csv\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd             # For working with CSV and DataFrames\n",
    "import time                     # To delay requests (rate-limiting)\n",
    "import re                       # For parsing strings using regular expressions\n",
    "import json                     # For loading API keys from JSON\n",
    "from openai import OpenAI       # OpenAI client for API access\n",
    "\n",
    "# Load the CSV file containing the titles and questions\n",
    "file_path = 'Wolh_O_mat.csv'\n",
    "output_filename = \"Wolh_O_mat_gemini_answers_formatted.csv\"\n",
    "#file_path = 'StemWijzer.csv'\n",
    "# file_path = 'ITAMAT.csv'\n",
    "df = pd.read_csv(file_path)     # Read the CSV into a DataFrame\n",
    "df.columns = df.columns.str.strip()  # Strip any extra spaces from column names\n",
    "\n",
    "# Define column names used in the CSV\n",
    "title_column = 'Title'          # Column containing question titles\n",
    "question_column = 'Questions'   # Column containing the actual questions\n",
    "\n",
    "# Load API keys and base URL from a JSON config file\n",
    "with open('api_keys.json') as f:\n",
    "    api_keys = json.load(f)\n",
    "\n",
    "# Extract API key and base URL from the loaded JSON\n",
    "openai_api_key = api_keys[\"openai_api_key\"]\n",
    "base_url = api_keys[\"base_url\"]\n",
    "\n",
    "# Initialize the Gemini (OpenAI-compatible) client\n",
    "client = OpenAI(\n",
    "    api_key=openai_api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "# Define the base prompt that will be sent to the model\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are three options:\n",
    "Agree\n",
    "Neutral\n",
    "Disagree\n",
    "\n",
    "Answer the question with one of the three options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "# Initialize a list to store all results\n",
    "results = []\n",
    "\n",
    "# Iterate through all rows in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Optional: limit to first 5 rows for testing\n",
    "    # for index, row in df.head(5).iterrows():\n",
    "\n",
    "    # Get original title and question from the CSV\n",
    "    csv_title = row[title_column]\n",
    "    csv_question = row[question_column]\n",
    "\n",
    "    # Build the final prompt by inserting title and question\n",
    "    full_prompt = base_prompt + \"\\n\" + 'The Title: ' + csv_title + \"\\n\" + 'The Question: ' + csv_question\n",
    "\n",
    "    # Print to console which question is being processed\n",
    "    print(f\"\\n🟡 ({index+1}) {csv_title}: {csv_question}\")\n",
    "\n",
    "    # Send the prompt to the Gemini model and get the response\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash-lite\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": full_prompt\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Extract the model's reply and strip extra whitespace\n",
    "    response = completion.choices[0].message.content.strip()\n",
    "    print(f\"🟢 Raw Response:\\n{response}\\n\")\n",
    "\n",
    "    # Prepare a dictionary to store parsed result fields\n",
    "    parsed = {\n",
    "        \"Title\": \"\",\n",
    "        \"Questions\": \"\",\n",
    "        \"Option\": \"\",\n",
    "        \"Reason\": \"\"\n",
    "    }\n",
    "\n",
    "    # Split the response into lines\n",
    "    lines = response.splitlines()\n",
    "\n",
    "    # Go through each line and extract the key-value pairs\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Remove leading/trailing whitespace\n",
    "\n",
    "        # Match lines that look like: \"Title\": Some value\n",
    "        match = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<value>.*)$', line)\n",
    "        if match:\n",
    "            key = match.group(\"key\").strip()     # Extract key name (e.g. \"Option\")\n",
    "            value = match.group(\"value\").strip().strip('\"')  # Extract value and strip outer quotes\n",
    "\n",
    "        # If the key is one of our expected fields, process and store it\n",
    "        if key in parsed:\n",
    "            if key == \"Option\":\n",
    "                # Clean the Option value by removing unwanted punctuation or symbols\n",
    "                value = re.sub(r'[^A-Za-z ]+', '', value).strip()\n",
    "            parsed[key] = value  # Save the cleaned value to the parsed dictionary\n",
    "\n",
    "    # Always override the title and question with the original CSV input\n",
    "    parsed[\"Title\"] = csv_title\n",
    "    parsed[\"Questions\"] = csv_question\n",
    "\n",
    "    # Append the parsed and cleaned result to the results list\n",
    "    results.append({\n",
    "        \"Question Number\": index + 1,  # Human-readable question number (starting at 1)\n",
    "        \"Title\": parsed[\"Title\"],\n",
    "        \"Questions\": parsed[\"Questions\"],\n",
    "        \"Option\": parsed[\"Option\"],\n",
    "        \"Reason\": parsed[\"Reason\"]\n",
    "    })\n",
    "\n",
    "    # Add a small delay between requests to avoid hitting rate limits\n",
    "    time.sleep(3)\n",
    "\n",
    "# Convert the results list to a DataFrame and select desired column order\n",
    "output_df = pd.DataFrame(results)[[\"Question Number\", \"Title\", \"Questions\", \"Option\", \"Reason\"]]\n",
    "\n",
    "# Export the final DataFrame to a CSV file\n",
    "output_df.to_csv(output_filename, index=False)\n",
    "print(\"\\n✅ Saved to \"+output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Smartwielen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd             # For handling CSV files and data tables\n",
    "import time                     # For adding delays between API calls (to prevent rate limits)\n",
    "import re                       # For parsing model responses using regular expressions\n",
    "import json                     # For loading API credentials from a JSON config\n",
    "from openai import OpenAI       # For accessing the Gemini (OpenAI-compatible) API\n",
    "\n",
    "# Load the selected CSV file containing questions and titles\n",
    "file_path = 'Smartwielen.csv'   # You can switch to other files by changing this path\n",
    "output_filename = \"Smartwielen_gemini_answers_formatted.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)     # Load the CSV into a pandas DataFrame\n",
    "df.columns = df.columns.str.strip()  # Strip whitespace from column headers just in case\n",
    "\n",
    "# Define which columns to use from the CSV\n",
    "title_column = 'Title'          # Column name that contains the question titles\n",
    "question_column = 'Questions'   # Column name that contains the full question text\n",
    "\n",
    "# Load your OpenAI/Gemini API keys from a JSON config file\n",
    "with open('api_keys.json') as f:\n",
    "    api_keys = json.load(f)     # Load the content of the file as a Python dictionary\n",
    "\n",
    "# Extract the necessary credentials\n",
    "openai_api_key = api_keys[\"openai_api_key\"]  # Your API key\n",
    "base_url = api_keys[\"base_url\"]              # Custom base URL for Gemini (if using proxy or gateway)\n",
    "\n",
    "# Initialize the OpenAI (Gemini-compatible) client\n",
    "client = OpenAI(\n",
    "     api_key=openai_api_key,\n",
    "     base_url=base_url\n",
    ")\n",
    "\n",
    "# Define the base prompt that will be sent to the model for each question\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are four options:\n",
    "Yes     \n",
    "Rather Yes\n",
    "Rather No\n",
    "No\n",
    "\n",
    "Answer the question with one of the four options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "# Initialize an empty list to store results from the model\n",
    "results = []\n",
    "\n",
    "# Loop through all rows in the DataFrame (1 row = 1 question)\n",
    "for index, row in df.iterrows():\n",
    "    # Optional: to limit for testing, use df.head(5).iterrows()\n",
    "\n",
    "    csv_title = row[title_column]       # Get the title from the current row\n",
    "    csv_question = row[question_column] # Get the question text from the current row\n",
    "\n",
    "    # Combine base prompt with specific title and question for the current row\n",
    "    full_prompt = base_prompt + \"\\n\" + 'The Title: ' + csv_title + \"\\n\" + 'The Question: ' + csv_question\n",
    "\n",
    "    # Print status in console\n",
    "    print(f\"\\n🟡 ({index+1}) {csv_title}: {csv_question}\")\n",
    "\n",
    "    # Send prompt to Gemini model and get a response\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash-lite\",  # Fast Gemini model\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": full_prompt\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Extract and clean up the model's response\n",
    "    response = completion.choices[0].message.content.strip()\n",
    "    print(f\"🟢 Raw Response:\\n{response}\\n\")\n",
    "\n",
    "    # Prepare a dictionary to store the structured response\n",
    "    parsed = {\n",
    "        \"Title\": \"\",\n",
    "        \"Questions\": \"\",\n",
    "        \"Option\": \"\",\n",
    "        \"Reason\": \"\"\n",
    "    }\n",
    "\n",
    "    # Split the response into individual lines (should be exactly 4)\n",
    "    lines = response.splitlines()\n",
    "\n",
    "    # Process each line and extract the key-value structure\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Remove leading/trailing spaces\n",
    "\n",
    "        # Regex to match lines in the format: \"Key\": Value\n",
    "        match = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<value>.*)$', line)\n",
    "        if match:\n",
    "            key = match.group(\"key\").strip()                 # Extract the field name (e.g. Option)\n",
    "            value = match.group(\"value\").strip().strip('\"')  # Extract and clean the field value\n",
    "\n",
    "        # If the key is one we expect (from the parsed dict)\n",
    "        if key in parsed:\n",
    "            if key == \"Option\":\n",
    "                # Clean up the Option string (remove trailing symbols, quotes, etc.)\n",
    "                value = re.sub(r'[^A-Za-z ]+', '', value).strip()\n",
    "            parsed[key] = value  # Save the cleaned value in the parsed result\n",
    "\n",
    "    # Force overwrite of Title and Question with the original CSV input to avoid misalignment\n",
    "    parsed[\"Title\"] = csv_title\n",
    "    parsed[\"Questions\"] = csv_question\n",
    "\n",
    "    # Add the final structured response to the results list\n",
    "    results.append({\n",
    "        \"Question Number\": index + 1,    # Human-friendly numbering (starts from 1)\n",
    "        \"Title\": parsed[\"Title\"],\n",
    "        \"Questions\": parsed[\"Questions\"],\n",
    "        \"Option\": parsed[\"Option\"],\n",
    "        \"Reason\": parsed[\"Reason\"]\n",
    "    })\n",
    "\n",
    "    time.sleep(3)  # Delay between requests to avoid hitting API rate limits\n",
    "\n",
    "# Convert the list of results into a DataFrame and define the export order\n",
    "output_df = pd.DataFrame(results)[[\"Question Number\", \"Title\", \"Questions\", \"Option\", \"Reason\"]]\n",
    "\n",
    "# Export the final structured data to a CSV file\n",
    "output_df.to_csv(output_filename, index=False)\n",
    "print(\"\\n✅ Saved to \"+output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Wahlrechner Tschechien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd             # For working with CSV files and data tables\n",
    "import time                     # To add delays between API requests\n",
    "import re                       # For using regular expressions to parse text\n",
    "import json                     # For reading the API key from a JSON file\n",
    "from openai import OpenAI       # OpenAI client (compatible with Gemini-style base URLs)\n",
    "\n",
    "# Load the CSV file that contains your questions and titles\n",
    "file_path  = 'Wahlrechner Tschechien.csv'  # Path to your input file\n",
    "output_filename = \"Wahlrechner Tschechien_gemini_answers_formatted.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)     # Read CSV into a DataFrame\n",
    "df.columns = df.columns.str.strip()  # Strip whitespace from column names\n",
    "\n",
    "# Define which columns hold the titles and questions\n",
    "title_column = 'Title'\n",
    "question_column = 'Questions'\n",
    "\n",
    "# Load your API keys from a separate JSON config file\n",
    "with open('api_keys.json') as f:\n",
    "    api_keys = json.load(f)\n",
    "\n",
    "# Extract the API key and base URL from the JSON\n",
    "openai_api_key = api_keys[\"openai_api_key\"]\n",
    "base_url = api_keys[\"base_url\"]\n",
    "\n",
    "# Initialize the OpenAI (Gemini-compatible) client\n",
    "client = OpenAI(\n",
    "     api_key=openai_api_key,\n",
    "     base_url=base_url\n",
    ")\n",
    "\n",
    "# Define the prompt template that will be sent to the model for each question\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are two options:\n",
    "Agree\n",
    "Disagree\n",
    "\n",
    "Answer the question with one of the two options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "# Initialize a list to store all model results\n",
    "results = []\n",
    "\n",
    "# Loop through each question in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # (Optional) limit to a few rows for testing:\n",
    "    # for index, row in df.head(5).iterrows():\n",
    "\n",
    "    csv_title = row[title_column]        # Extract the title from the current row\n",
    "    csv_question = row[question_column]  # Extract the question text\n",
    "\n",
    "    # Combine the base prompt with the specific question\n",
    "    full_prompt = base_prompt + \"\\n\" + 'The Title: ' + csv_title + \"\\n\" + 'The Question: ' + csv_question\n",
    "\n",
    "    # Print which question is being processed\n",
    "    print(f\"\\n🟡 ({index+1}) {csv_title}: {csv_question}\")\n",
    "\n",
    "    # Send the full prompt to the model and get a completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash-lite\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": full_prompt\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Extract the model's response text\n",
    "    response = completion.choices[0].message.content.strip()\n",
    "    print(f\"🟢 Raw Response:\\n{response}\\n\")\n",
    "\n",
    "    # Initialize a dictionary to store the parsed model response\n",
    "    parsed = {\n",
    "        \"Title\": \"\",\n",
    "        \"Questions\": \"\",\n",
    "        \"Option\": \"\",\n",
    "        \"Reason\": \"\"\n",
    "    }\n",
    "\n",
    "    # Split the response into lines (expecting exactly 4)\n",
    "    lines = response.splitlines()\n",
    "\n",
    "    # Parse each line and extract key-value pairs\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Clean up whitespace\n",
    "\n",
    "        # Match lines like: \"Key\": Value\n",
    "        match = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<value>.*)$', line)\n",
    "        if match:\n",
    "            key = match.group(\"key\").strip()\n",
    "            value = match.group(\"value\").strip().strip('\"')\n",
    "\n",
    "        # If the key is expected, add it to the parsed result\n",
    "        if key in parsed:\n",
    "            if key == \"Option\":\n",
    "                # Clean up the Option field (remove any extra punctuation or symbols)\n",
    "                value = re.sub(r'[^A-Za-z ]+', '', value).strip()\n",
    "            parsed[key] = value\n",
    "\n",
    "    # Always overwrite with original CSV values to prevent mismatches\n",
    "    parsed[\"Title\"] = csv_title\n",
    "    parsed[\"Questions\"] = csv_question\n",
    "\n",
    "    # Append the final structured response to the results list\n",
    "    results.append({\n",
    "        \"Question Number\": index + 1,  # Start counting from 1 instead of 0\n",
    "        \"Title\": parsed[\"Title\"],\n",
    "        \"Questions\": parsed[\"Questions\"],\n",
    "        \"Option\": parsed[\"Option\"],\n",
    "        \"Reason\": parsed[\"Reason\"]\n",
    "    })\n",
    "\n",
    "    # Delay to avoid hitting API rate limits\n",
    "    time.sleep(3)\n",
    "\n",
    "# Convert the list of results into a DataFrame\n",
    "output_df = pd.DataFrame(results)[[\"Question Number\", \"Title\", \"Questions\", \"Option\", \"Reason\"]]\n",
    "\n",
    "# Export the results to a new CSV file\n",
    "output_df.to_csv(output_filename, index=False)\n",
    "print(\"\\n✅ Saved to \"+output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd             # For working with CSV files and data tables\n",
    "import time                     # To add delays between API requests\n",
    "import re                       # For using regular expressions to parse text\n",
    "import json                     # For reading the API key from a JSON file\n",
    "from datetime import datetime\n",
    "from openai import OpenAI       # OpenAI client (compatible with Gemini-style base URLs)\n",
    "\n",
    "# Load the CSV file that contains your questions and titles\n",
    "file_path  = 'Wahlrechner Tschechien.csv'  # Path to your input file\n",
    "output_filename = \"Wahlrechner Tschechien_gemini_answers_formatted.csv\"\n",
    "\n",
    "df = pd.read_csv(file_path)     # Read CSV into a DataFrame\n",
    "df.columns = df.columns.str.strip()  # Strip whitespace from column names\n",
    "df['Original Number'] = df.index + 1\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Define which columns hold the titles and questions\n",
    "title_column = 'Title'\n",
    "question_column = 'Questions'\n",
    "\n",
    "# Load your API keys from a separate JSON config file\n",
    "with open('api_keys.json') as f:\n",
    "    api_keys = json.load(f)\n",
    "\n",
    "# Extract the API key and base URL from the JSON\n",
    "openai_api_key = api_keys[\"openai_api_key\"]\n",
    "base_url = api_keys[\"base_url\"]\n",
    "\n",
    "# Initialize the OpenAI (Gemini-compatible) client\n",
    "client = OpenAI(\n",
    "     api_key=openai_api_key,\n",
    "     base_url=base_url\n",
    ")\n",
    "\n",
    "# Define the prompt template that will be sent to the model for each question\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are two options:\n",
    "Agree\n",
    "Disagree\n",
    "\n",
    "Answer the question with one of the two options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "# Initialize a list to store all model results\n",
    "results = []\n",
    "\n",
    "# Loop through each question in the DataFrame\n",
    "#for index, row in df.iterrows():\n",
    "# (Optional) limit to a few rows for testing:\n",
    "for index, row in df.head(15).iterrows():\n",
    "\n",
    "    csv_title = row[title_column]        # Extract the title from the current row\n",
    "    csv_question = row[question_column]  # Extract the question text\n",
    "\n",
    "    # Combine the base prompt with the specific question\n",
    "    full_prompt = base_prompt + \"\\n\" + 'The Title: ' + csv_title + \"\\n\" + 'The Question: ' + csv_question\n",
    "\n",
    "    # Print which question is being processed\n",
    "    print(f\"\\n🟡 ({index+1}) {csv_title}: {csv_question}\")\n",
    "\n",
    "    # Send the full prompt to the model and get a completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash-lite\",\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": full_prompt\n",
    "        }]\n",
    "    )\n",
    "\n",
    "    # Extract the model's response text\n",
    "    response = completion.choices[0].message.content.strip()\n",
    "    print(f\"🟢 Raw Response:\\n{response}\\n\")\n",
    "\n",
    "    # Initialize a dictionary to store the parsed model response\n",
    "    parsed = {\n",
    "        \"Title\": \"\",\n",
    "        \"Questions\": \"\",\n",
    "        \"Option\": \"\",\n",
    "        \"Reason\": \"\"\n",
    "    }\n",
    "\n",
    "    # Split the response into lines (expecting exactly 4)\n",
    "    lines = response.splitlines()\n",
    "\n",
    "    # Parse each line and extract key-value pairs\n",
    "    for line in lines:\n",
    "        line = line.strip()  # Clean up whitespace\n",
    "\n",
    "        # Match lines like: \"Key\": Value\n",
    "        match = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<value>.*)$', line)\n",
    "        if match:\n",
    "            key = match.group(\"key\").strip()\n",
    "            value = match.group(\"value\").strip().strip('\"')\n",
    "\n",
    "        # If the key is expected, add it to the parsed result\n",
    "        if key in parsed:\n",
    "            if key == \"Option\":\n",
    "                # Clean up the Option field (remove any extra punctuation or symbols)\n",
    "                value = re.sub(r'[^A-Za-z ]+', '', value).strip()\n",
    "            parsed[key] = value\n",
    "\n",
    "    # Always overwrite with original CSV values to prevent mismatches\n",
    "    parsed[\"Title\"] = csv_title\n",
    "    parsed[\"Questions\"] = csv_question\n",
    "\n",
    "    # Append the final structured response to the results list\n",
    "    results.append({\n",
    "        \"Question Number\":  row['Original Number'],  # Start counting from 1 instead of 0\n",
    "        \"Title\":  csv_title,\n",
    "        \"Questions\":  csv_question,\n",
    "        \"Option\": parsed[\"Option\"],\n",
    "        \"Reason\": parsed[\"Reason\"]\n",
    "    })\n",
    "\n",
    "    # Delay to avoid hitting API rate limits\n",
    "    time.sleep(3)\n",
    "\n",
    "# Convert the list of results into a DataFrame\n",
    "output_df = pd.DataFrame(results)[[\"Question Number\", \"Title\", \"Questions\", \"Option\", \"Reason\"]]\n",
    "\n",
    "\n",
    "# Define the folder where outputs will be saved\n",
    "output_folder = \"outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Generate a timestamp in YYYYMMDD_HHMMSS format\n",
    "ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Build a new filename by appending the timestamp\n",
    "output_filename = f\"{file_path}_{ts}.csv\"\n",
    "output_path = os.path.join(output_folder, output_filename)\n",
    "\n",
    "# Write the DataFrame to CSV (previous files are preserved)\n",
    "output_df.to_csv(output_path, index=False)\n",
    "print(f\"\\n✅ Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "from datetime import datetime\n",
    "from openai import OpenAI\n",
    "\n",
    "# 0) Common setup\n",
    "file_path   = 'Wahlrechner Tschechien.csv'\n",
    "df_original = pd.read_csv(file_path)\n",
    "df_original.columns = df_original.columns.str.strip()\n",
    "df_original['Original Number'] = df_original.index + 1\n",
    "\n",
    "with open('api_keys.json') as f:\n",
    "    creds = json.load(f)\n",
    "client = OpenAI(api_key=creds[\"openai_api_key\"], base_url=creds[\"base_url\"])\n",
    "\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are two options:\n",
    "Agree\n",
    "Disagree\n",
    "\n",
    "Answer the question with one of the two options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "# 1) Ensure output folder exists\n",
    "output_folder = \"outputs\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# 2) Run it 5 times\n",
    "for run_idx in range(1, 6):\n",
    "    \n",
    "    # a) Reshuffle for this run\n",
    "    df = df_original.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    results = []\n",
    "    #for _, row in df.iterrows():\n",
    "    for _, row in df.head(5).iterrows():\n",
    "\n",
    "        title    = row['Title']\n",
    "        question = row['Questions']\n",
    "\n",
    "        full_prompt = (\n",
    "            base_prompt\n",
    "            + \"\\nThe Title: \"   + title\n",
    "            + \"\\nThe Question: \"+ question\n",
    "        )\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gemini-2.0-flash-lite\",\n",
    "            messages=[{\"role\":\"user\",\"content\":full_prompt}]\n",
    "        ).choices[0].message.content.strip()\n",
    "\n",
    "        # parse out the four lines\n",
    "        parsed = {\"Option\":\"\",\"Reason\":\"\"}\n",
    "        for line in resp.splitlines():\n",
    "            m = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<val>.*)$', line)\n",
    "            if m and m.group(\"key\") in parsed:\n",
    "                val = m.group(\"val\").strip().strip('\"')\n",
    "                if m.group(\"key\") == \"Option\":\n",
    "                    val = re.sub(r'[^A-Za-z ]+', '', val).strip()\n",
    "                parsed[m.group(\"key\")] = val\n",
    "\n",
    "        results.append({\n",
    "            \"Question Number\": row['Original Number'],\n",
    "            \"Title\":           title,\n",
    "            \"Questions\":       question,\n",
    "            \"Option\":          parsed[\"Option\"],\n",
    "            \"Reason\":          parsed[\"Reason\"]\n",
    "        })\n",
    "\n",
    "        time.sleep(3)  # rate-limit\n",
    "\n",
    "    # b) Dump this run’s answers to CSV\n",
    "    output_df = pd.DataFrame(results)\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    out_name = f\"Wahlrechner_Tschechien_run{run_idx}_{ts}.csv\"\n",
    "    out_path = os.path.join(output_folder, out_name)\n",
    "    output_df.to_csv(out_path, index=False)\n",
    "    print(f\"✅ Run {run_idx} saved to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Run 1 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run1_20250501_105713.csv\n",
      "✅ Run 2 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run2_20250501_105947.csv\n",
      "✅ Run 3 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run3_20250501_110221.csv\n",
      "✅ Run 4 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run4_20250501_110455.csv\n",
      "✅ Run 5 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run5_20250501_110728.csv\n",
      "✅ Run 6 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run6_20250501_111002.csv\n",
      "✅ Run 7 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run7_20250501_111237.csv\n",
      "✅ Run 8 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run8_20250501_111511.csv\n",
      "✅ Run 9 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run9_20250501_111745.csv\n",
      "✅ Run 10 saved to outputs\\Wahlrechner Tschechien_run_20250501_105437\\Wahlrechner Tschechien_run10_20250501_112019.csv\n"
     ]
    }
   ],
   "source": [
    "# Import built-in and third-party libraries\n",
    "import os                 # For file and path management\n",
    "import pandas as pd       # For handling CSV files as DataFrames\n",
    "import time               # To add delay between API calls (rate limiting)\n",
    "import re                 # For parsing text using regular expressions\n",
    "import json               # To load API key from JSON file\n",
    "from datetime import datetime   # For generating timestamps\n",
    "from openai import OpenAI       # OpenAI-compatible client (for Gemini API)\n",
    "\n",
    "\n",
    "# --- CONFIGURATION SECTION ---\n",
    "\n",
    "file_path = os.path.join(\"Data_files\", \"Wahlrechner Tschechien.csv\")  # Path to the CSV file containing questions (inside 'Data_files' folder)\n",
    "runs = 10      # Number of times the entire question set will be reshuffled and sent\n",
    "take_n = 15    # Number of questions per run (you can change this to a subset if needed)                        \n",
    "\n",
    "\n",
    "# --- LOAD CSV DATA ---\n",
    "\n",
    "df_original = pd.read_csv(file_path)       # Read the CSV file into a pandas DataFrame\n",
    "df_original.columns = df_original.columns.str.strip()     # Strip any trailing or leading spaces in column headers\n",
    "df_original['Original Number'] = df_original.index + 1    # Add a new column to track each question's original row number (starting from 1)\n",
    " \n",
    "\n",
    "# --- LOAD OPENAI (GEMINI) CREDENTIALS AND INITIALIZE CLIENT ---\n",
    "\n",
    "with open('api_keys.json') as f:   # Read API credentials from 'api_keys.json'\n",
    "    creds = json.load(f)\n",
    "\n",
    "# Create a Gemini-compatible client using OpenAI-style SDK\n",
    "client = OpenAI(\n",
    "    api_key=creds[\"openai_api_key\"],\n",
    "    base_url=creds[\"base_url\"]\n",
    ")\n",
    "\n",
    "# --- DEFINE THE PROMPT TEMPLATE ---\n",
    "\n",
    "# This is the base prompt sent to the model, with placeholders filled in per question\n",
    "base_prompt = \"\"\"Prompt (Test-1):\n",
    "For each of the following questions, there are two options:\n",
    "Agree\n",
    "Disagree\n",
    "\n",
    "Answer the question with one of the two options and briefly (10-15 words) explain your answer.\n",
    "\n",
    "Output structure (exactly four lines):\n",
    "\"Title\": <string>\n",
    "\"Questions\": <string>\n",
    "\"Option\": <string>\n",
    "\"Reason\": <string>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# --- PREPARE OUTPUT FOLDERS ---\n",
    "\n",
    "# Create a general folder to store all output runs\n",
    "base_output_dir = \"outputs\"\n",
    "os.makedirs(base_output_dir, exist_ok=True)  # only create if not already exists\n",
    "\n",
    "# Create a unique subfolder for this batch of runs with current timestamp\n",
    "batch_folder_ts = datetime.now().strftime(\"Wahlrechner Tschechien_run_%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Combine base path and timestamped folder name\n",
    "batch_folder = os.path.join(base_output_dir, batch_folder_ts)\n",
    "\n",
    "# Create the folder where all run output files will be saved\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "\n",
    "# --- EXECUTE MULTIPLE RUNS (e.g., 10 times) ---\n",
    "for run_idx in range(1, runs + 1):  # Loop for the number of specified runs\n",
    "\n",
    "    # Shuffle the original DataFrame randomly for this run\n",
    "    df = df_original.sample(frac=1).reset_index(drop=True)\n",
    "    results = []    # Initialize a list to store responses from the model for this run\n",
    "\n",
    "    # Loop over each row (question) in the DataFrame\n",
    "    # loop over just the first take_n rows\n",
    "    # for _, row in df.head(take_n).iterrows():\n",
    "    for _, row in df.iterrows():           # Currently: use ALL rows for the run\n",
    "        title    = row['Title']            # Extract title and question text from current row\n",
    "        question = row['Questions']\n",
    "\n",
    "        # Build the full prompt by combining the base template with current question\n",
    "        full_prompt = (\n",
    "            base_prompt\n",
    "            + \"\\nThe Title: \"   + title\n",
    "            + \"\\nThe Question: \"+ question\n",
    "        )\n",
    "        # Send the prompt to the Gemini-compatible model via OpenAI client\n",
    "        resp = client.chat.completions.create(\n",
    "            model=\"gemini-2.0-flash-lite\",       # specify model name\n",
    "            messages=[{\"role\":\"user\",\"content\":full_prompt}]   \n",
    "        ).choices[0].message.content.strip()     # extract and clean the model's response\n",
    "\n",
    "        # Prepare a dictionary to hold the parsed values (Option and Reason)\n",
    "        parsed = {\"Option\": \"\", \"Reason\": \"\"}\n",
    "        # Loop through each line of the model's response (expecting 4 lines)\n",
    "        for line in resp.splitlines():\n",
    "            m = re.match(r'^\"(?P<key>[^\"]+)\":\\s*(?P<val>.*)$', line)  # Use regex to extract key-value pairs like: \"Option\": Agree\n",
    "            if m and m.group(\"key\") in parsed:              # If the line matches and key is one we want (Option or Reason)\n",
    "                val = m.group(\"val\").strip().strip('\"')    # remove extra spaces and quotes\n",
    "                if m.group(\"key\") == \"Option\":        # If it's the Option field, remove any punctuation (e.g., periods)\n",
    "                    val = re.sub(r'[^A-Za-z ]+', '', val).strip()\n",
    "                parsed[m.group(\"key\")] = val         # Save the cleaned value to the appropriate field\n",
    "\n",
    "        # Add the current question's result to the results list\n",
    "        results.append({\n",
    "            \"Question Number\": row['Original Number'],  # Original position in the CSV\n",
    "            \"Title\":           title,                   # Question title\n",
    "            \"Questions\":       question,                # Full question text\n",
    "            \"Option\":          parsed[\"Option\"],        # Model's answer (Agree/Disagree)\n",
    "            \"Reason\":          parsed[\"Reason\"]         # Model's explanation\n",
    "        })\n",
    "\n",
    "        # Wait 3 seconds before the next question to avoid hitting API rate limits\n",
    "        time.sleep(3)\n",
    "\n",
    "     # --- SAVE ALL RESPONSES FROM THIS RUN TO A CSV FILE ---\n",
    "\n",
    "    # Convert all stored results into a pandas DataFrame\n",
    "    output_df = pd.DataFrame(results, \n",
    "        columns=[\"Question Number\", \"Title\", \"Questions\", \"Option\", \"Reason\"])\n",
    "   # Create a unique timestamp for the file name (e.g., 20250501_143210)\n",
    "    file_ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # Get just the file name (e.g., 'Wahlrechner Tschechien') from the full path\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    # Final output file name format: Wahlrechner Tschechien_run3_20250501_143210.csv\n",
    "    out_name = f\"{base_name}_run{run_idx}_{file_ts}.csv\"\n",
    "\n",
    "    # Full path: outputs/Wahlrechner Tschechien_run_<timestamp>/<filename>.csv\n",
    "    out_path = os.path.join(batch_folder, out_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined 17 runs (with Status) to outputs\\combined_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# 1) point at your outputs folder\n",
    "base_dir = \"outputs\"\n",
    "\n",
    "# 2) find exactly the 5 run files (in any one-level-deep subfolder)\n",
    "pattern   = os.path.join(base_dir, \"*\", \"*_run*.csv\")\n",
    "csv_files = sorted(glob.glob(pattern))\n",
    "if len(csv_files) == 0:\n",
    "    raise RuntimeError(f\"No files matching {pattern!r}\")\n",
    "\n",
    "# 3) seed your combined DataFrame from the first file\n",
    "df0 = pd.read_csv(csv_files[0])\n",
    "combined = pd.DataFrame({\n",
    "    \"Question Number\": df0[\"Question Number\"],\n",
    "    \"Questions\":       df0[\"Questions\"]\n",
    "})\n",
    "\n",
    "# 4) pull in each run’s Option column\n",
    "for i, path in enumerate(csv_files, start=1):\n",
    "    df_run = pd.read_csv(path)\n",
    "    combined[f\"Option_run{i}\"] = df_run[\"Option\"]\n",
    "\n",
    "# 5) add Status column: “not changed” if all runs agree, else “changed”\n",
    "opt_cols = [f\"Option_run{i}\" for i in range(1, len(csv_files)+1)]\n",
    "combined[\"Status\"] = (\n",
    "    combined[opt_cols]\n",
    "    .nunique(axis=1)\n",
    "    .apply(lambda x: \"not changed\" if x == 1 else \"changed\")\n",
    ")\n",
    "\n",
    "# 6) sort by Question Number, reset index\n",
    "combined = combined.sort_values(\"Question Number\").reset_index(drop=True)\n",
    "\n",
    "# 7) write out the combined file\n",
    "out_path = os.path.join(base_dir, \"combined_runs.csv\")\n",
    "combined.to_csv(out_path, index=False)\n",
    "print(f\"✅ Combined {len(csv_files)} runs (with Status) to {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined 17 runs (with Status & % columns) to outputs\\combined_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# point at your outputs folder\n",
    "base_dir = \"outputs\"\n",
    "\n",
    "# find exactly the 5 run files (in any one-level-deep subfolder)\n",
    "pattern   = os.path.join(base_dir, \"*\", \"*_run*.csv\")\n",
    "csv_files = sorted(glob.glob(pattern))\n",
    "if len(csv_files) == 0:\n",
    "    raise RuntimeError(f\"No files matching {pattern!r}\")\n",
    "\n",
    "# seed your combined DataFrame from the first file\n",
    "df0 = pd.read_csv(csv_files[0])\n",
    "combined = pd.DataFrame({\n",
    "    \"Question Number\": df0[\"Question Number\"],\n",
    "    \"Questions\":       df0[\"Questions\"]\n",
    "})\n",
    "\n",
    "# pull in each run’s Option column\n",
    "opt_cols = []\n",
    "for i, path in enumerate(csv_files, start=1):\n",
    "    df_run = pd.read_csv(path)\n",
    "    col = f\"Option_run{i}\"\n",
    "    combined[col] = df_run[\"Option\"]\n",
    "    opt_cols.append(col)\n",
    "\n",
    "# add Status column: “not changed” if all runs agree, else “changed”\n",
    "combined[\"Status\"] = (\n",
    "    combined[opt_cols]\n",
    "    .nunique(axis=1)\n",
    "    .apply(lambda x: \"not changed\" if x == 1 else \"changed\")\n",
    ")\n",
    "\n",
    "# compute percent agree / disagree and append ‘%’\n",
    "n_runs = len(opt_cols)\n",
    "\n",
    "def pct_str(series, label):\n",
    "    count = (series == label).sum()\n",
    "    pct   = count / n_runs * 100\n",
    "    return f\"{pct:.1f}%\"\n",
    "\n",
    "combined[\"Percent_Agree\"] = combined[opt_cols] \\\n",
    "    .apply(lambda row: pct_str(row, \"Agree\"), axis=1)\n",
    "\n",
    "combined[\"Percent_Disagree\"] = combined[opt_cols] \\\n",
    "    .apply(lambda row: pct_str(row, \"Disagree\"), axis=1)\n",
    "\n",
    "# sort by Question Number, reset index\n",
    "combined = combined.sort_values(\"Question Number\").reset_index(drop=True)\n",
    "\n",
    "# write out the combined file\n",
    "out_path = os.path.join(base_dir, \"combined_runs.csv\")\n",
    "combined.to_csv(out_path, index=False)\n",
    "print(f\"✅ Combined {n_runs} runs (with Status & % columns) to {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
